{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d13e52",
   "metadata": {},
   "source": [
    "# Using MCP Tools with Azure AI Foundry Agents\n",
    "\n",
    "This notebook demonstrates how to use Model Context Protocol (MCP) tools with Azure AI Foundry agents. Azure AI Foundry provides seamless integration with hosted MCP servers, eliminating infrastructure management while providing secure, controlled access to external tools.\n",
    "\n",
    "## What You'll Learn:\n",
    "- Basic hosted MCP tool integration with Azure AI Foundry agents\n",
    "- Multi-tool MCP configuration with different approval modes\n",
    "- Azure AI observability for monitoring and tracing\n",
    "- Microsoft Learn MCP server integration for documentation queries\n",
    "\n",
    "## Key Features:\n",
    "- **Hosted MCP Server**: Managed by Azure AI Foundry, no infrastructure to maintain\n",
    "- **Persistent Agents**: Server-side agent creation with stateful conversations\n",
    "- **Tool Approval Workflow**: Configurable approval mechanisms for MCP tool invocations\n",
    "- **Observability**: Built-in monitoring and tracing for production scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86384ede",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. **Azure AI Project**: Access to an Azure AI Foundry project with deployed models\n",
    "2. **Authentication**: Azure CLI installed and authenticated (`az login --use-device-code`)\n",
    "3. **Environment Variables**: Set up your `.env` file with connection details\n",
    "4. **Dependencies**: Required agent-framework packages installed\n",
    "\n",
    "If you need to use a different tenant, specify the tenant ID:\n",
    "```bash\n",
    "az login --tenant <tenant-id>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adb63e",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import the required libraries for Azure AI agent functionality with MCP integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5efd7b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking environment variables...\n",
      "‚úÖ AZURE_AI_PROJECT_ENDPOINT: https://agentic-ai-labs.services.ai.azure.com/api/...\n",
      "‚úÖ AZURE_AI_MODEL_DEPLOYMENT_NAME: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agent_framework import HostedMCPTool\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "# Verify required environment variables\n",
    "print(\"Checking environment variables...\")\n",
    "endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "model = os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "if endpoint:\n",
    "    print(f\"‚úÖ AZURE_AI_PROJECT_ENDPOINT: {endpoint[:50]}...\")\n",
    "    print(f\"‚úÖ AZURE_AI_MODEL_DEPLOYMENT_NAME: {model}\")\n",
    "else:\n",
    "    print(\"‚ùå AZURE_AI_PROJECT_ENDPOINT is not set!\")\n",
    "    print(\"Please configure your .env file with the required variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb287e",
   "metadata": {},
   "source": [
    "## Example 1: Basic MCP Integration\n",
    "\n",
    "This example demonstrates the simplest way to create an Azure AI Foundry agent with a hosted MCP tool. The agent can search Microsoft Learn documentation to answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad0a4cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure AI observability enabled\n",
      "\n",
      "ü§ñ Creating MicrosoftLearnAgent with hosted MCP tool...\n",
      "‚úÖ Created agent: MicrosoftLearnAgent\n",
      "\n",
      "ü§î Query: Please summarize the Azure AI Agent documentation related to MCP tool calling?\n",
      "\n",
      "ü§ñ Response:\n",
      "Azure AI Agent's Model Context Protocol (MCP) integration allows AI agents to dynamically leverage external tools and services for enhanced capabilities. Below is a summary of key documentation points about MCP tool-calling:\n",
      "\n",
      "1. **Enabling MCP Tools in Agents:**\n",
      "   - Azure AI agents can use MCP tools by connecting to MCP servers (custom, self-hosted, or Databricks-managed).\n",
      "   - MCP servers provide tools for real-time data, APIs, or service access.\n",
      "   - To initialize an MCP-enabled agent, provide server configuration details (e.g., endpoint URL, tool labels, authentication).\n",
      "\n",
      "2. **Agent Integration with MCP:**\n",
      "   - Tools can be added to agents via Azure AI Foundry or Visual Studio Code extensions.\n",
      "   - Configuration involves registering MCP tools in the agent's workflow with approval options (e.g., always, never, or specific tools).\n",
      "   - Server tools are invoked as needed to answer queries.\n",
      "\n",
      "3. **Tool Development with MCP:**\n",
      "   - AI agents can expose their functionality as MCP tools for reuse by other agents.\n",
      "   - Tools can handle tasks like REST API calls, data search, or custom computation.\n",
      "\n",
      "4. **Interoperability and Hosting Considerations:**\n",
      "   - MCP tools can be developed in multiple programming languages (e.g., Python, C#).\n",
      "   - MCP servers can be hosted on Azure Functions or other environments, supporting scalability and reusability.\n",
      "   - Python or C# agents can expose themselves as MCP tools via server integration.\n",
      "\n",
      "5. **Use Cases and Prototyping:**\n",
      "   - Ideal for complex agent workflows requiring advanced data access or external integrations.\n",
      "   - Prototyping supported via AI Playground, allowing evaluation of MCP-enabled agents.\n",
      "   - Foundry and Databricks serve as popular options for deploying and testing tool configurations.\n",
      "\n",
      "6. **Governance with Tools:**\n",
      "   - MCP tools offer standardized methodology for integrating tools, improving governance, and maintaining interoperability.\n",
      "   - Tools can be synchronous (MCP) or asynchronous (e.g., via Azure Queues).\n",
      "\n",
      "For detailed steps on creating, exposing, and integrating MCP tools, refer to the [Microsoft Learn Guide on MCP Tools](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol-samples?view=foundry-classic).\n",
      "\n",
      "‚úÖ Basic example completed!\n"
     ]
    }
   ],
   "source": [
    "async def basic_foundry_mcp_example():\n",
    "    \"\"\"Basic example of Azure AI Foundry agent with hosted MCP tools.\"\"\"\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as chat_client,\n",
    "    ):\n",
    "        # Enable Azure AI observability (optional but recommended)\n",
    "        #print(\"üîç Setting up Azure AI observability...\")\n",
    "        #await chat_client.setup_azure_ai_observability()\n",
    "        print(\"‚úÖ Azure AI observability enabled\\n\")\n",
    "\n",
    "        # Create agent with hosted MCP tool\n",
    "        print(\"ü§ñ Creating MicrosoftLearnAgent with hosted MCP tool...\")\n",
    "        agent = chat_client.create_agent(\n",
    "            name=\"MicrosoftLearnAgent\", \n",
    "            instructions=\"You answer questions by searching Microsoft Learn content only.\",\n",
    "            tools=HostedMCPTool(\n",
    "                name=\"Microsoft Learn MCP\",\n",
    "                url=\"https://learn.microsoft.com/api/mcp\",\n",
    "                approval_mode=\"never_require\",  # Auto-approve tool calls\n",
    "            ),\n",
    "        )\n",
    "        print(f\"‚úÖ Created agent: {agent.name}\\n\")\n",
    "\n",
    "        # Simple query without approval workflow\n",
    "        query = \"Please summarize the Azure AI Agent documentation related to MCP tool calling?\"\n",
    "        print(f\"ü§î Query: {query}\\n\")\n",
    "        \n",
    "        result = await agent.run(query)\n",
    "        \n",
    "        print(f\"ü§ñ Response:\\n{result.text}\")\n",
    "        print(f\"\\n‚úÖ Basic example completed!\")\n",
    "\n",
    "# Run the basic example (use await in notebooks, asyncio.run() in scripts)\n",
    "await basic_foundry_mcp_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2515b",
   "metadata": {},
   "source": [
    "## Example 2: Multi-Tool MCP Configuration\n",
    "\n",
    "This example demonstrates using multiple hosted MCP tools with different approval modes. This is useful when you want to integrate multiple external services with varying security requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure AI observability enabled\n",
      "\n",
      "ü§ñ Creating MultiToolAgent with multiple MCP tools...\n",
      "‚úÖ Created agent: MultiToolAgent\n",
      "\n",
      "ü§î Query: What are the key features of Azure AI Foundry?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-01 15:39:24 - /Users/anuragkaruparti/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework_azure_ai/_chat_client.py:676 - ERROR] Error processing stream: MCP Connector error. Http status: 424, error details: Error retrieving tool list from MCP server: 'GitHub_MCP'. Http status code: 404 (Not Found)\n"
     ]
    },
    {
     "ename": "ServiceResponseException",
     "evalue": "MCP Connector error. Http status: 424, error details: Error retrieving tool list from MCP server: 'GitHub_MCP'. Http status code: 404 (Not Found)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Multi-tool example completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Run the multi-tool example\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m multi_tool_mcp_example()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mmulti_tool_mcp_example\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mWhat are the key features of Azure AI Foundry?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mü§î Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m agent.run(query)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mü§ñ Response:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresult.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Multi-tool example completed!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework/_middleware.py:1249\u001b[39m, in \u001b[36muse_agent_middleware.<locals>.middleware_enabled_run\u001b[39m\u001b[34m(self, messages, thread, middleware, **kwargs)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m AgentRunResponse()\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# No middleware, execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_run(\u001b[38;5;28mself\u001b[39m, normalized_messages, thread=thread, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework/observability.py:1106\u001b[39m, in \u001b[36m_trace_agent_run.<locals>.trace_run\u001b[39m\u001b[34m(self, messages, thread, **kwargs)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1105\u001b[39m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_func(\u001b[38;5;28mself\u001b[39m, messages=messages, thread=thread, **kwargs)\n\u001b[32m   1107\u001b[39m attributes = _get_span_attributes(\n\u001b[32m   1108\u001b[39m     operation_name=OtelAttr.AGENT_INVOKE_OPERATION,\n\u001b[32m   1109\u001b[39m     provider_name=provider_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1115\u001b[39m     **kwargs,\n\u001b[32m   1116\u001b[39m )\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _get_span(attributes=attributes, span_name_attribute=OtelAttr.AGENT_NAME) \u001b[38;5;28;01mas\u001b[39;00m span:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework/_agents.py:871\u001b[39m, in \u001b[36mChatAgent.run\u001b[39m\u001b[34m(self, messages, thread, allow_multiple_tool_calls, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_chat_options, **kwargs)\u001b[39m\n\u001b[32m    849\u001b[39m     final_tools.extend(mcp_server.functions)\n\u001b[32m    851\u001b[39m co = run_chat_options & ChatOptions(\n\u001b[32m    852\u001b[39m     model_id=model_id,\n\u001b[32m    853\u001b[39m     conversation_id=thread.service_thread_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     **(additional_chat_options \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    870\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chat_client.get_response(messages=thread_messages, chat_options=co, **kwargs)\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._update_thread_with_type_and_conversation_id(thread, response.conversation_id)\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Ensure that the author name is set for each message in the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework/_tools.py:1567\u001b[39m, in \u001b[36m_handle_function_calls_response.<locals>.decorator.<locals>.function_invocation_wrapper\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1565\u001b[39m     _replace_approval_contents_with_results(prepped_messages, fcc_todo, approved_function_results)\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, messages=prepped_messages, **kwargs)\n\u001b[32m   1568\u001b[39m \u001b[38;5;66;03m# if there are function calls, we will handle them first\u001b[39;00m\n\u001b[32m   1569\u001b[39m function_results = {\n\u001b[32m   1570\u001b[39m     it.call_id \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m response.messages[\u001b[32m0\u001b[39m].contents \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(it, FunctionResultContent)\n\u001b[32m   1571\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework/observability.py:836\u001b[39m, in \u001b[36m_trace_get_response.<locals>.decorator.<locals>.trace_get_response\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m    835\u001b[39m     \u001b[38;5;66;03m# If model_id diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\n\u001b[32m    837\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    838\u001b[39m         messages=messages,\n\u001b[32m    839\u001b[39m         **kwargs,\n\u001b[32m    840\u001b[39m     )\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.additional_properties:\n\u001b[32m    842\u001b[39m     \u001b[38;5;28mself\u001b[39m.additional_properties[\u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m] = _get_token_usage_histogram()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework/_middleware.py:1367\u001b[39m, in \u001b[36muse_chat_middleware.<locals>.middleware_enabled_get_response\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;66;03m# If no chat middleware, use original method\u001b[39;00m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_middleware_list:\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_get_response(\u001b[38;5;28mself\u001b[39m, messages, **kwargs)\n\u001b[32m   1369\u001b[39m \u001b[38;5;66;03m# Create pipeline and execute with middleware\u001b[39;00m\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOptions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework/_clients.py:577\u001b[39m, in \u001b[36mBaseChatClient.get_response\u001b[39m\u001b[34m(self, messages, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_properties, **kwargs)\u001b[39m\n\u001b[32m    574\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_tool_choice(chat_options=chat_options)\n\u001b[32m    576\u001b[39m filtered_kwargs = \u001b[38;5;28mself\u001b[39m._filter_internal_kwargs(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_response(messages=prepped_messages, chat_options=chat_options, **filtered_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework_azure_ai/_chat_client.py:264\u001b[39m, in \u001b[36mAzureAIAgentClient._inner_get_response\u001b[39m\u001b[34m(self, messages, chat_options, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_inner_get_response\u001b[39m(\n\u001b[32m    258\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    262\u001b[39m     **kwargs: Any,\n\u001b[32m    263\u001b[39m ) -> ChatResponse:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ChatResponse.from_chat_response_generator(\n\u001b[32m    265\u001b[39m         updates=\u001b[38;5;28mself\u001b[39m._inner_get_streaming_response(messages=messages, chat_options=chat_options, **kwargs),\n\u001b[32m    266\u001b[39m         output_format_type=chat_options.response_format,\n\u001b[32m    267\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework/_types.py:2519\u001b[39m, in \u001b[36mChatResponse.from_chat_response_generator\u001b[39m\u001b[34m(cls, updates, output_format_type)\u001b[39m\n\u001b[32m   2499\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Joins multiple updates into a single ChatResponse.\u001b[39;00m\n\u001b[32m   2500\u001b[39m \n\u001b[32m   2501\u001b[39m \u001b[33;03mExample:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2516\u001b[39m \u001b[33;03m    output_format_type: Optional Pydantic model type to parse the response text into structured data.\u001b[39;00m\n\u001b[32m   2517\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2518\u001b[39m msg = \u001b[38;5;28mcls\u001b[39m(messages=[])\n\u001b[32m-> \u001b[39m\u001b[32m2519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m updates:\n\u001b[32m   2520\u001b[39m     _process_update(msg, update)\n\u001b[32m   2521\u001b[39m _finalize_response(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework_azure_ai/_chat_client.py:290\u001b[39m, in \u001b[36mAzureAIAgentClient._inner_get_streaming_response\u001b[39m\u001b[34m(self, messages, chat_options, **kwargs)\u001b[39m\n\u001b[32m    287\u001b[39m agent_id = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_agent_id_or_create(run_options)\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Process and yield each update from the stream\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_stream(\n\u001b[32m    291\u001b[39m     *(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_agent_stream(thread_id, agent_id, run_options, required_action_results))\n\u001b[32m    292\u001b[39m ):\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m update\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework_azure_ai/_chat_client.py:576\u001b[39m, in \u001b[36mAzureAIAgentClient._process_stream\u001b[39m\u001b[34m(self, stream, thread_id)\u001b[39m\n\u001b[32m    567\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m ChatResponseUpdate(\n\u001b[32m    568\u001b[39m                 role=Role.ASSISTANT,\n\u001b[32m    569\u001b[39m                 contents=function_call_contents,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m                 response_id=response_id,\n\u001b[32m    574\u001b[39m             )\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m AgentStreamEvent.THREAD_RUN_FAILED:\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(event_data.last_error.message)\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m ChatResponseUpdate(\n\u001b[32m    579\u001b[39m         contents=[],\n\u001b[32m    580\u001b[39m         conversation_id=event_data.thread_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    585\u001b[39m         model_id=event_data.model,\n\u001b[32m    586\u001b[39m     )\n",
      "\u001b[31mServiceResponseException\u001b[39m: MCP Connector error. Http status: 424, error details: Error retrieving tool list from MCP server: 'GitHub_MCP'. Http status code: 404 (Not Found)"
     ]
    }
   ],
   "source": [
    "async def multi_tool_mcp_example():\n",
    "    \"\"\"Example using multiple hosted MCP tools with different approval modes.\"\"\"\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as chat_client,\n",
    "    ):\n",
    "        #print(\"üîç Setting up Azure AI observability...\")\n",
    "        #await chat_client.setup_azure_ai_observability()\n",
    "        print(\"‚úÖ Azure AI observability enabled\\n\")\n",
    "\n",
    "        # Create agent with multiple MCP tools\n",
    "        print(\"ü§ñ Creating MultiToolAgent with multiple MCP tools...\")\n",
    "        agent = chat_client.create_agent(\n",
    "            name=\"MultiToolAgent\",\n",
    "            instructions=\"You can search documentation and provide comprehensive answers.\",\n",
    "            tools=[\n",
    "                HostedMCPTool(\n",
    "                    name=\"Microsoft Learn MCP\",\n",
    "                    url=\"https://learn.microsoft.com/api/mcp\",\n",
    "                    approval_mode=\"never_require\",  # Auto-approve documentation searches\n",
    "                ),\n",
    "                # Note: Add more MCP tools here as needed\n",
    "                #Example with custom headers:\n",
    "                HostedMCPTool(\n",
    "                    name=\"GitHub MCP\", \n",
    "                    url=\"https://api.github.com/mcp\",\n",
    "                    approval_mode=\"always_require\",  # Require approval for GitHub operations\n",
    "                    headers={\"Authorization\": f\"Bearer {os.getenv('GITHUB_TOKEN')}\"},\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        print(f\"‚úÖ Created agent: {agent.name}\\n\")\n",
    "\n",
    "        # Query that will use the MCP tools\n",
    "        query = \"What are the key features of Azure AI Foundry?\"\n",
    "        print(f\"ü§î Query: {query}\\n\")\n",
    "        \n",
    "        result = await agent.run(query)\n",
    "        \n",
    "        print(f\"ü§ñ Response:\\n{result.text}\")\n",
    "        print(f\"\\n‚úÖ Multi-tool example completed!\")\n",
    "\n",
    "# Run the multi-tool example\n",
    "await multi_tool_mcp_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74bdee0",
   "metadata": {},
   "source": [
    "## Example 3: Thread-Based Conversation with MCP Tools\n",
    "\n",
    "This example demonstrates how to use threads to maintain conversation context across multiple queries while using hosted MCP tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "041cf8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Creating DocsAgent with Microsoft Learn MCP...\n",
      "‚úÖ Created agent: DocsAgent\n",
      "\n",
      "üìù Created new conversation thread\n",
      "\n",
      "=== Query 1 ===\n",
      "ü§î User: How to create an Azure storage account using az cli?\n",
      "\n",
      "ü§ñ DocsAgent: To create an Azure storage account using the Azure CLI, you can use the following command format:\n",
      "\n",
      "```azurecli\n",
      "az storage account create \\\n",
      "  --name <STORAGE_ACCOUNT_NAME> \\\n",
      "  --resource-group <RESOURCE_GROUP_NAME> \\\n",
      "  --location <LOCATION> \\\n",
      "  --sku <SKU> \\\n",
      "  --kind <KIND>\n",
      "```\n",
      "\n",
      "### Example\n",
      "\n",
      "For a basic storage account in the `westus` region with locally redundant storage (Standard_LRS), you could use:\n",
      "```azurecli\n",
      "az storage account create \\\n",
      "  --name MyStorageAccount \\\n",
      "  --resource-group MyResourceGroup \\\n",
      "  --location westus \\\n",
      "  --sku Standard_LRS \\\n",
      "  --kind StorageV2\n",
      "```\n",
      "\n",
      "Here:\n",
      "- `--name`: Specifies the name of the storage account.\n",
      "- `--resource-group`: The resource group where the storage account will be placed.\n",
      "- `--location`: Specifies the Azure region (e.g., `westus`, `eastus`).\n",
      "- `--sku`: Defines the replication strategy and performance tier. For example, `Standard_LRS` (Locally Redundant Storage).\n",
      "- `--kind`: Type of the storage account such as `Storage`, `StorageV2`, or `BlobStorage`.\n",
      "\n",
      "For more details, visit the [Azure CLI documentation for creating a storage account](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-create-cli).\n",
      "\n",
      "Let me know if further clarification is needed!\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚è≥ Waiting before next query...\n",
      "=== Query 2 ===\n",
      "ü§î User: What is Foundry\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-01 15:20:44 - /Users/anuragkaruparti/agentic-ai-lab/.venv/lib/python3.12/site-packages/agent_framework_azure_ai/_chat_client.py:676 - ERROR] Error processing stream: Sorry, something went wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Second query failed: Sorry, something went wrong.\n",
      "üí° This can happen with MCP tools - try running again\n",
      "\n",
      "‚úÖ Thread-based conversation completed!\n"
     ]
    }
   ],
   "source": [
    "async def thread_based_mcp_example():\n",
    "    \"\"\"Example showing thread-based conversation with hosted MCP tools.\"\"\"\n",
    "    import asyncio\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as chat_client,\n",
    "    ):\n",
    "        print(\"ü§ñ Creating DocsAgent with Microsoft Learn MCP...\")\n",
    "        agent = chat_client.create_agent(\n",
    "            name=\"DocsAgent\",\n",
    "            instructions=\"You are a helpful assistant that can help with Microsoft documentation questions.\",\n",
    "            tools=HostedMCPTool(\n",
    "                name=\"Microsoft Learn MCP\",\n",
    "                url=\"https://learn.microsoft.com/api/mcp\",\n",
    "                approval_mode=\"never_require\",\n",
    "            ),\n",
    "        )\n",
    "        print(f\"‚úÖ Created agent: {agent.name}\\n\")\n",
    "        \n",
    "        thread = agent.get_new_thread()\n",
    "        print(f\"üìù Created new conversation thread\\n\")\n",
    "        \n",
    "        # First query\n",
    "        query1 = \"How to create an Azure storage account using az cli?\"\n",
    "        print(f\"=== Query 1 ===\")\n",
    "        print(f\"ü§î User: {query1}\\n\")\n",
    "        result1 = await agent.run(query1, thread=thread, store=True)\n",
    "        print(f\"ü§ñ {agent.name}: {result1.text}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        \n",
    "        # Add delay before second query\n",
    "        print(\"‚è≥ Waiting before next query...\")\n",
    "        await asyncio.sleep(2)\n",
    "        \n",
    "        # Second query\n",
    "        query2 = \"What is Foundry\"\n",
    "        print(f\"=== Query 2 ===\")\n",
    "        print(f\"ü§î User: {query2}\\n\")\n",
    "        try:\n",
    "            result2 = await agent.run(query2, thread=thread, store=True)\n",
    "            print(f\"ü§ñ {agent.name}: {result2.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Second query failed: {e}\")\n",
    "            print(\"üí° This can happen with MCP tools - try running again\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Thread-based conversation completed!\")\n",
    "\n",
    "await thread_based_mcp_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df86da",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Hosted MCP Tools**: Enable integration with external Model Context Protocol servers\n",
    "2. **User Approval Workflows**: Provide security by requiring consent for function calls\n",
    "3. **Thread Management**: Maintain conversation context across multiple queries\n",
    "4. **Azure AI Observability**: Built-in monitoring and tracing for agent interactions\n",
    "5. **Microsoft Learn Integration**: Access to comprehensive Microsoft documentation\n",
    "6. **Error Handling**: Robust error handling for production scenarios\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Security First**: Always implement proper approval workflows for function calls\n",
    "2. **Observability**: Enable Azure AI observability for monitoring and debugging\n",
    "3. **Thread Management**: Use threads to maintain conversation context\n",
    "4. **Error Handling**: Implement comprehensive error handling for reliability\n",
    "5. **Custom Approvals**: Tailor approval logic to your specific security requirements\n",
    "6. **Resource Cleanup**: Properly manage agent and thread lifecycles\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "- **Documentation Assistance**: AI-powered help with Microsoft technologies\n",
    "- **Technical Support**: Automated support with human oversight\n",
    "- **Knowledge Management**: Organizational knowledge base integration\n",
    "- **Training and Education**: Interactive learning with documentation\n",
    "- **Code Generation**: Context-aware code examples and templates\n",
    "- **Compliance**: Secure function execution with approval workflows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
